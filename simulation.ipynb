{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Wan 2.2 Distributed Inference Simulation\n",
        "\n",
        "This notebook simulates the execution of a Wan 2.2 Video Generation workflow across a logical pool of heterogeneous GPUs (Kaggle T4s, Colab L4s).\n",
        "\n",
        "It demonstrates:\n",
        "1.  **VRAM-aware Scheduling**: Assigning tasks to workers that fit.\n",
        "2.  **FSDP / Model Sharding**: Automatically splitting large models (FP16) across multiple workers when they exceed single-GPU capacity.\n",
        "3.  **Pipeline Parallelism**: Distributing the graph (TextEnc -> UNet -> VAE) across the pool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import json\n",
        "from wan_pool.controller import Controller\n",
        "from wan_pool.worker import Worker, WorkerType, DeviceType\n",
        "\n",
        "# 1. Setup the Logical Cluster\n",
        "# We mimic a typical distributed setup: 2x T4 (Kaggle), 1x L4 (Colab), 1x CPU (Local)\n",
        "\n",
        "workers = [\n",
        "    Worker(worker_id=\"w1\", name=\"Kaggle_T4_A\", w_type=WorkerType.KAGGLE, vram_gb=15.0),\n",
        "    Worker(worker_id=\"w2\", name=\"Kaggle_T4_B\", w_type=WorkerType.KAGGLE, vram_gb=15.0),\n",
        "    Worker(worker_id=\"w3\", name=\"Colab_L4\",    w_type=WorkerType.COLAB,  vram_gb=22.0),\n",
        "    Worker(worker_id=\"w4\", name=\"Local_CPU\",   w_type=WorkerType.LOCAL,  vram_gb=32.0, device=DeviceType.CPU)\n",
        "]\n",
        "\n",
        "controller = Controller(workers)\n",
        "print(\"Cluster initialized.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Load the ComfyUI Workflow\n",
        "# We use the JSON provided in the prompt (Wan 2.2 14B I2V)\n",
        "# Note: We will modify the model filenames in the next steps to trigger different behaviors.\n",
        "\n",
        "workflow_template = {\n",
        "  \"id\": \"job_wan_14b\",\n",
        "  \"nodes\": [\n",
        "    {\n",
        "      \"id\": 1, \"type\": \"CLIPTextEncode\",\n",
        "      \"widgets_values\": [\"a cinematic shot of a robot\"],\n",
        "      \"inputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"id\": 2, \"type\": \"UNETLoader\",\n",
        "      \"widgets_values\": [\"wan2.2_14b_fp8.safetensors\"]\n",
        "    },\n",
        "    {\n",
        "      \"id\": 3, \"type\": \"ModelSampling\",\n",
        "      \"inputs\": [{\"name\": \"model\", \"link\": 20}]\n",
        "    },\n",
        "    {\n",
        "      \"id\": 4, \"type\": \"KSampler\",\n",
        "      \"inputs\": [\n",
        "          {\"name\": \"model\", \"link\": 30},\n",
        "          {\"name\": \"positive\", \"link\": 10}\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"id\": 5, \"type\": \"VAELoader\",\n",
        "      \"widgets_values\": [\"wan_vae.safetensors\"]\n",
        "    },\n",
        "    {\n",
        "      \"id\": 6, \"type\": \"VAEDecode\",\n",
        "      \"inputs\": [\n",
        "          {\"name\": \"samples\", \"link\": 40},\n",
        "          {\"name\": \"vae\", \"link\": 50}\n",
        "      ]\n",
        "    }\n",
        "  ],\n",
        "  \"links\": [\n",
        "    [10, 1, 0, 4, 1, \"CONDITIONING\"],\n",
        "    [20, 2, 0, 3, 0, \"MODEL\"],\n",
        "    [30, 3, 0, 4, 0, \"MODEL\"],\n",
        "    [40, 4, 0, 6, 0, \"LATENT\"],\n",
        "    [50, 5, 0, 6, 1, \"VAE\"]\n",
        "  ]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scenario A: FP8 Inference (Standard)\n",
        "The model is `wan2.2_14b_fp8.safetensors`. This is approximately **14GB**.\n",
        "- **Kaggle T4 (15GB)**: Fits (tightly).\n",
        "- **Colab L4 (22GB)**: Fits comfortably.\n",
        "\n",
        "Expected Behavior: The Planner should assign the UNet to one of the T4s or the L4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import copy\n",
        "job_fp8 = copy.deepcopy(workflow_template)\n",
        "# Ensure filename implies FP8\n",
        "job_fp8[\"nodes\"][1][\"widgets_values\"] = [\"wan2.2_14b_fp8.safetensors\"]\n",
        "\n",
        "controller.submit_job(job_fp8)\n",
        "await controller.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scenario B: FP16 Inference (Oversized / FSDP)\n",
        "The model is `wan2.2_14b_fp16.safetensors`. This is approximately **28GB**.\n",
        "- **Kaggle T4 (15GB)**: Too small.\n",
        "- **Colab L4 (22GB)**: Too small.\n",
        "\n",
        "Expected Behavior: The Planner must detect that no single worker fits 28GB. It should form a **Virtual Worker Group** (e.g., T4_A + T4_B = 30GB, or T4 + L4) and split the task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "job_fp16 = copy.deepcopy(workflow_template)\n",
        "# Rename to FP16 to trigger size estimation of ~28GB\n",
        "job_fp16[\"nodes\"][1][\"widgets_values\"] = [\"wan2.2_14b_fp16.safetensors\"]\n",
        "\n",
        "controller.submit_job(job_fp16)\n",
        "await controller.run()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
